{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin: 30px 15px 15px 15px;\" src=\"https://pngimage.net/wp-content/uploads/2018/06/logo-iteso-png-5.png\" width=\"300\" height=\"500\" /> \n",
    "    \n",
    "    \n",
    "### <font color='navy'> Simulación de procesos financieros. \n",
    "\n",
    "**Nombres:** Valeria Ladrón de Guevara y Pablo Muñoz.\n",
    "\n",
    "**Fecha:** 02 de julio del 2021.\n",
    "\n",
    "**Expediente** : if714513; if719963 .\n",
    "**Profesor:** Oscar David Jaramillo Zuluaga.\n",
    "    \n",
    "**Link Github**: https://github.com/valerialadron/Tarea9_VLadron_PMu-oz\n",
    "\n",
    "# Tarea 9: Clase 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = red> Tarea\n",
    "\n",
    "Demostrar **Teoricamente** usando el MLE, que los estimadores de máxima verosimilitud para los parámetros $\\mu$ y $\\sigma$ de una distribución normal, estan dados por:\n",
    "\n",
    "$$\\hat \\mu = {1\\over n}\\sum_{i=1}^n x_i,\\quad \\hat  \\sigma^2={1\\over n}\\sum_{i=1}^n (x_i-\\hat \\mu)^2$$\n",
    "\n",
    "**Recuerde que:** La distribución normal es\n",
    "$$f(x\\mid \\mu ,\\sigma ^{2})={\\frac {1}{\\sqrt {2\\pi \\sigma ^{2}}}}e^{-{\\frac {(x-\\mu )^{2}}{2\\sigma ^{2}}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código Valeria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de solución estudiante 1\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código Pablo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código de solución Pablo Muñoz\n",
    "# MLE para probar los parámetros $\\mu$  y $\\sigma$\n",
    "\n",
    "### Asumimos 2 cosas\n",
    "- La información está independientemente distribuida\n",
    "- La información está identicamente distribuida "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ubicaremos los parámetros de la siguiente manera\n",
    "\n",
    "$$ \\theta = \\{\\mu, \\sigma\\}$$\n",
    "\n",
    "- Organizaremos el problema como un problema de probabilidad condicional, con la meta de maximizar la probabilidad de observar nuestra información dado $\\theta$. \n",
    "- Para nuestro problema, tenemos una data de tamaño \"n\", y se vería de la siguiente forma.\n",
    "\n",
    "$$ P(x_1, x_2, ...  x_n | \\theta) $$\n",
    "\n",
    "- Pero nosotros estamos tratando con distribución de probabilidad continua, no con probabilidad, entonces la forma correcta sería:\n",
    "\n",
    "$$ P(x_1, x_2, ...  x_n | \\theta)  \\rightarrow  f(x_1, x_2, ...  x_n | \\theta) $$\n",
    "\n",
    "- Y buscamos maximizar la densidad de probabilidad, entonces queremos encontrar que valores de $\\mu$ y $\\sigma$ obtenemos el mayor valor. Para este caso $\\theta$ será nuestra variable independiente, y consideraremos $x_1, x_2, ... x_n$ como constantes.\n",
    "\n",
    "- De probabilidad aprendims que la probabilidad de multiples eventos independientes se llama _probabilidad conjunta_, y podemos tratar a cada pujnto como un evento individual. Si hacemos esto, la podemos aplicarlo de la siguiente forma a nuestra densidad de probabilidad.\n",
    "\n",
    "$$ f(x_1, x_2, ...  x_n | \\theta) = f(x_1|\\theta) * f(x_2|\\theta) * ... * f(x_n|\\theta) = \\prod_{i}^nf(x_i|\\theta)$$\n",
    "\n",
    "- Como buscamos maximizar, debemos retomarnos a nuestras clases de cálculo diferencial y derivar. Si aplicamos el logaritmo natural del producto anterior obtendremos lo siguiente:\n",
    "\n",
    "$$ \\ln(\\prod(f)) = \\sum\\ln(f)$$\n",
    "\n",
    "$$\\frac{d}{d\\theta}\\sum\\ln(f(x_1|\\theta)) = 0$$\n",
    "\n",
    "- Cambiamos $\\theta$ a una notación gradiente:\n",
    "\n",
    "$$\\frac{d}{d\\theta}\\sum\\ln(f(x_1|\\theta)) = \\sum_{i}^n\\triangledown_{\\mu,\\sigma}\\ln(f(x_1|\\mu,\\sigma)) = 0 $$ \n",
    "\n",
    "- Primero tomamos el gradiente $\\triangledown$ con respecto a $\\mu$. Sustituimos la PDF de una distribución normal con $f(x_i|\\mu,\\sigma)$:\n",
    "\n",
    "$$ \\sum_{i}^n\\triangledown_{\\mu}\\ln(\\frac{\\sigma\\sqrt{2\\pi}}{e}^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}) = 0$$\n",
    "\n",
    "- Usando propiedades de los logaritmos podemos simplificar:\n",
    "\n",
    "$$ \\sum_{i}^n\\triangledown_{\\mu} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2}$$\n",
    "\n",
    "- Después,\n",
    "$$ \\sum_{i}^n\\triangledown_{\\mu} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2} = - \\frac{1}{2\\sigma^2} \\sum_{i}^n \\triangledown_{\\mu} (x_i - \\mu)^2$$\n",
    "\n",
    "$$ = - \\frac{1}{2\\sigma^2} \\sum_{i}^n \\triangledown_{\\mu} (x_i - \\mu)^2 = \\frac{1}{\\sigma^2}\\sum_{i}^n (x_i - \\mu)$$\n",
    "\n",
    "- Si igualamos esto último a 0 obtendremos lo que estamos buscando\n",
    "\n",
    "$$ \\frac{1}{\\sigma^2}\\sum_{i}^n (x_i - \\mu) = 0 \\rightarrow \\hat{\\mu}_{MLE} = \\frac{1}{n}\\sum_i^n x_i$$\n",
    "\n",
    "- Esto nos dice que nuestra $\\mu$ óptima es independiente de nuestro valor $\\sigma$ óptimo. Ahora tomaremos el gradiente con respecto a $\\sigma$ e iniciamos desde la simplificación de logaritmos que hicimos anteriormente\n",
    "\n",
    "$$ \\sum_{i}^n\\triangledown_{\\sigma} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2}$$\n",
    "\n",
    "$$ \\sum_{i}^n\\triangledown_{\\sigma} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(x_i - \\mu)^2}{2\\sigma^2} = - \\frac{n}{2}\\triangledown_{\\sigma} \\ln\\sigma^2 - \\frac{1}{2}\\triangledown_{\\sigma}(\\frac{1}{\\sigma^2}\\sum_i^n(x_i - \\mu)^2)$$\n",
    "\n",
    "- Simplificamos por última vez e igualamos a 0 para obtener la solución:\n",
    "\n",
    "$$ = -\\frac{n}{\\sigma} + \\frac{1}{\\sigma^3}\\sum_i^n(x_i - \\mu)^2$$ \n",
    "\n",
    "$$ -\\frac{n}{\\sigma} + \\frac{1}{\\sigma^3}\\sum_i^n(x_i - \\mu)^2 = 0$$ \n",
    "\n",
    "$$\\sum_i^n(x_i - \\mu)^2 = n\\sigma^2 \\rightarrow \\hat{\\sigma^2}_{MLE} = \\frac{1}{n}\\sum_i^n(x_i - \\mu)^2$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
